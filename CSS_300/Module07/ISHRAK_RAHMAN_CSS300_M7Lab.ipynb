{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# CSS 300 | Spring 2025 | Module 7 | Lab Activity\n",
    "<hr style=\"border: 5px solid #0072CE;\" />\n",
    "\n",
    "##### *The very first thing you should do: rename this file by replacing \"YOURNAME\" with your actual first name. For this assignment, you only need to submit this Jupyter notebook.\n",
    "\n",
    "#### Bottom line: make sure that the instructor can run all cells in your Jupyter notebook without errors occurring!\n",
    "\n",
    "If you find yourself uncertain about how to do something, you should (in order):\n",
    "\n",
    "- Have a look at the [`pandas` API reference](https://pandas.pydata.org/docs/reference/index.html)\n",
    "- Consider also the [`Mathplotlib`](https://matplotlib.org/stable/api/index.html) and [`Seaborn`](https://seaborn.pydata.org/api.html) API references\n",
    "- Ask Lucas or a Learning Support Specialist for help\n",
    "\n",
    "*You are reminded that the use of generative AI in CSS 300, in any shape or form, is considered academic dishonesty and will result in a grade of zero (and possibly worse!).*\n",
    "\n",
    "### Imports go here (feel free to import more libraries if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure you run (but do not delete anything from) this cell!\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "# Part 0 — Preliminaries (no work required here, but please read and run code as requested)\n",
    "First, let's recall the four steps in the modeling process:\n",
    "\n",
    "1. Define a model.\n",
    "\n",
    "2. Choose a loss function and calculate the average loss on our dataset.\n",
    "\n",
    "3. Find the best value of $\\theta$, known as $\\hat\\theta$, that minimizes loss. There can be multiple such values.\n",
    "\n",
    "4. Evaluate the model performance (not covered in this lab).\n",
    "\n",
    "In class, we learnt all about a modelling technique known as **simple linear regression**. The goal of this lab is to implement this in practice. Before anything, we need some data! For this lab, we'll make use of a really convenient example dataset from `Seaborn` called `tips`. It's nice to work with because we don't need to grab a `.csv` file or anything; all we need to do is run `sns.load_dataset()`, and we get a `pandas` `DataFrame` that's ready to be worked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below loads a \"tips\" dataset from an online repository. Note that an internet connection is required.\n",
    "# Make sure you run (but do not delete anything from) this cell!\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to what we're used to, this is a relatively small `DataFrame`: 244 rows and 7 columns. You should have a little think about what each row represents here, and what each of the variables mean.\n",
    "\n",
    "Here is our specific task: **we want to predict *restaurant tips* from the `tips` `DataFrame` given information about the *total bill***.\n",
    "\n",
    "In other words, all our work today will involve following the **modeling process** described in class in order to use `\"total_bill\"` to compute *predicted* tips. As in class, our observations are pairs $(x_i, y_i)$, where $x_i$ is the `\"total_bill\"` in the $i$th row, and $y_i$ is the `\"tip\"` in the $i$th row.\n",
    "\n",
    "For convenience, we will store the $x$ and $y$ variables in `NumPy` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to define x and y array; no further action needed.\n",
    "y_tips = np.array(tips['tip'])               # Array of observed tips\n",
    "x_total_bills = np.array(tips['total_bill']) # Array of total bill amounts\n",
    "\n",
    "# You should see that these arrays have the same shape:\n",
    "print(\"Shape of \\'x_total_bills\\': \", x_total_bills.shape)\n",
    "print(\"Shape of \\'y_tips\\': \", y_tips.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "# Part 1 — Define a model (no work required here, but please read)\n",
    "\n",
    "We will define our model as the **linear model** that takes a single input feature, `total_bill`, $x$, and predicts the dependent variable, $\\hat{y}$:\n",
    "\n",
    "$$\\large\n",
    "\\hat{y} = \\theta_0 + \\theta_1 x\n",
    "$$\n",
    "\n",
    "$\\theta_0$ and $\\theta_1$ are what we call **parameters**. Our modeling goal is to find the value of our parameter(s) that **best** fit our data.\n",
    "\n",
    "We have a choice over which $\\theta_0$ and $\\theta_1$ we pick (using the data at hand), but ultimately we can only pick one to report, so we want to find the **optimal parameter(s)** $\\hat{\\theta_0}$ and $\\hat{\\theta_1}$.\n",
    "\n",
    "Our modeling task is then to pick the best values $\\theta_0 = \\hat{\\theta}_0$ and $\\theta_1 = \\hat{\\theta_1}$ from our data. \n",
    "\n",
    "Then, given the total bill $x$, we can predict the tip as $\\hat{y} = \\hat{\\theta}_0 + \\hat{\\theta}_1 x$.\n",
    "\n",
    "No code to write here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "# Part 2 — Define a loss function\n",
    "\n",
    "Next, in order to pick our $\\theta_0$ and $\\theta_1$, we need to define a **loss function**, which is a measure of how well a model is able to predict the expected outcome. In other words, it measures the deviation of the observed value $y$ from the predicted value $\\hat{y}$.\n",
    "\n",
    "We will use **squared loss** (also known as the $L_2$ loss, pronounced \"ell-two\"). For an observed tip value $y$ (i.e., the real tip), our prediction of the tip $\\hat{y}$ would give an $L_2$ loss of:\n",
    "\n",
    "$$\\large L_2(y, \\hat{y}) = \\large (y - \\hat{y})^2 = \\large (y - (\\theta_0 + \\theta_1 x))^2 $$\n",
    "\n",
    "\n",
    "We just defined loss for a single data point. Let's extend the above function to our entire dataset by taking the **average loss** across the dataset.\n",
    "\n",
    "We can think of all our observations as the collection $(x_1, y_1), \\ldots, (x_n, y_n)$, where $(x_i, y_i)$ are the $i^{th}$ total bill and tip, respectively, in our dataset.\n",
    "\n",
    "We can then define the average loss over the dataset using squared loss (also known as **Mean Squared Error (MSE)**) as:\n",
    "\n",
    "$$\\large R(\\theta_0, \\theta_1) = \\large \\frac{1}{n} \\sum_{i=1}^n L(y_i, \\hat{y}_i) $$\n",
    "$$= \\large \\frac{1}{n} \\sum_{i = 1}^n(y_i - (\\theta_0 + \\theta_1 x_i))^2\n",
    "$$\n",
    "\n",
    "If you're a little confused by the symbol \"$\\Sigma$\", check out this [Wikipedia article](https://en.wikipedia.org/wiki/Summation#Capital-sigma_notation) for an explanation.\n",
    "\n",
    "### Question 2(a)\n",
    "\n",
    "Define the `mse_tips_linear` function which implements $R(\\theta_0, \\theta_1)$ (the **Mean Squared Error (MSE)** function) defined above.\n",
    "\n",
    "**Hint:**\n",
    "* This function takes in two parameters `theta0` and `theta1`.\n",
    "* You should use the `NumPy` arrays `x_total_bills` and `y_tips` defined in Part 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_tips_linear(theta0, theta1):\n",
    "    \"\"\"\n",
    "    Calculate the mean square error on the tips data for a linear model.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    theta0 : intercept of the fitted linear model\n",
    "    theta1 : slope of the fitted linear model\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    The mean square error on the tips data for a linear model.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(x_total_bills)\n",
    "    total = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        x_i = x_total_bills[i]\n",
    "        y_i = y_tips[i]\n",
    "        mse = ((y_i - (theta0 + theta1 * x_i)) ** 2)\n",
    "        total = total + mse\n",
    "\n",
    "    return total * 1/n\n",
    "\n",
    "\n",
    "mse_tips_linear(0.9, 0.1) # Arbitrarily pick theta0 = 0.9, theta1 = 0.1, and see what your MSE ends up being!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "# Part 3 — Find the best value of $\\theta$\n",
    "Now we can go about choosing our **best** value of $\\theta = \\left(\\theta_0, \\theta_1\\right)$, \n",
    "which we call $\\hat{\\theta}$, that minimizes our MSE.\n",
    "\n",
    "In class, we derived the following **optimal** parameters $\\hat{\\theta}_1$ and $\\hat{\\theta}_0$:\n",
    "\n",
    "$$\\large \\hat{\\theta}_1 = r \\cdot \\frac{s_y}{s_x}$$\n",
    "\n",
    "\n",
    "$$\\large \\hat{\\theta}_0 = \\bar{y} - \\hat{\\theta}_1\\bar{x}$$\n",
    "\n",
    "and the prediction of the tip of the $i^{th}$ bill, $\\hat{y_i}$, will be:\n",
    "$$\\large \\hat{y}_i = \\hat{\\theta}_0 + \\hat{\\theta}_1x_i$$\n",
    "\n",
    "where $\\bar{x}$, $\\bar{y}$, $s_x$, $s_y$ correspond to the means and standard deviations of $x$ and $y$, respectively, and $r$ is the correlation coefficient.\n",
    "\n",
    "## Question 3(a)\n",
    "Assign `x_bar`, `y_bar`, `std_x`, `std_y`, and `r`, for our dataset. \n",
    "\n",
    "**Hint:**\n",
    "\n",
    "* Remember that, in our case, `y` is `y_tips`, and `x` is `x_total_bills`.\n",
    "* You may find the following functions useful for computing mean and (sample) standard deviation: `np.mean()` ([documentation](https://numpy.org/doc/2.2/reference/generated/numpy.mean.html)) and `np.std()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.std.html))\n",
    "* You may find `np.corrcoef` [(documentation)](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html) handy in computing `r`. Note that the output of `np.corrcoef` is a matrix, not a number, so you'll need to collect the correlation coefficient by *indexing* (similar to how you'd index a `list`) in the returned matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Question 3(a) goes here\n",
    "x_bar = np.mean(x_total_bills)\n",
    "y_bar = np.mean(y_tips)\n",
    "x_sd =  np.std(x_total_bills)\n",
    "y_sd =  np.std(y_tips)\n",
    "r = np.corrcoef(x_total_bills, y_tips)[0, 1]\n",
    "print(x_bar, y_bar, x_sd, y_sd, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is worth noting what value of $r$ you end up getting! Does it tell you that linear regression is appropriate in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3(b)\n",
    "Now, define `theta0_hat` and `theta1_hat` (i.e. $\\hat{\\theta_0}$ and $\\hat{\\theta_1}$ correctly, in terms of the variables you defined above. For easy reading, you should use the Python `round()` function ([documentation](https://docs.python.org/3/library/functions.html#round)) to round both numbers to three decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1_hat = r * (y_sd / x_sd)\n",
    "theta0_hat = y_bar - theta1_hat * x_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you're done, run the code below to get a visualization of your hard work. Even though all the code is written for you, you should read and (eventually) understand it all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== No work required here! =====================\n",
    "\n",
    "# ---------------- First, plot the linear regression line -------------------\n",
    "# Given a fixed slope and initial value together with inputs x, this function returns the output y = mx + b\n",
    "def linear_function(x, m, b):\n",
    "  return m * x + b\n",
    "\n",
    "# Create a NumPy array of x values\n",
    "x_values = np.linspace(x_total_bills.min(), x_total_bills.max(), 1000)  # Generates 1000 points between min and max of x-values\n",
    "\n",
    "# Create a NumPy array of corresponding y values\n",
    "y_values = linear_function(x_values, theta1_hat, theta0_hat)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(x_values, y_values, label=f'y = {theta1_hat}x + {theta0_hat}', color='red')\n",
    "\n",
    "\n",
    "# ---------------- Next, plot our actual data from the tips DataFrame -------------------\n",
    "# Scatterplot\n",
    "plt.scatter(x=x_total_bills, y=y_tips)\n",
    "\n",
    "# ---------------- Finishing touches -------------------\n",
    "# Add labels and title\n",
    "plt.xlabel('Total Bill ($)')\n",
    "plt.ylabel('Tips ($)')\n",
    "plt.title('Tip Amount VS Total Bill — Simple Linear Regression')\n",
    "\n",
    "# Add a grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a legend so we can see what function this is\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Some extra stuff before you go, just for fun:\n",
    "\n",
    "With `Seaborn`, you can accomplish a data viz nearly identical to the graph you created with not very much code (see the next cell). However, `Seaborn` only shows you a picture; you accomplished a little more through this lab by finding the values of the optimal parameters $\\hat{\\theta_0}$ and $\\hat{\\theta_1}$!\n",
    "\n",
    "Run the code in the cell below to see how Seaborn does simple linear regression (this should also serve as a hint for what your viz should look like!). Here's the [documentation](https://seaborn.pydata.org/generated/seaborn.regplot.html) for `sns.regplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== No work required here! =====================\n",
    "\n",
    "# Plot both our data and a linear regression model fit.\n",
    "# Note that the NumPy arrays from Part 0 need to be defined for this code to work!\n",
    "\n",
    "# ---------------- Linear regression plot -------------------\n",
    "sns.regplot(x=x_total_bills, y=y_tips, line_kws=dict(color=\"r\"), ci=None)\n",
    "\n",
    "# ---------------- Finishing touches -------------------\n",
    "# Add labels and title\n",
    "plt.xlabel('Total Bill ($)')\n",
    "plt.ylabel('Tips ($)')\n",
    "plt.title('Tip Amount VS Total Bill — Simple Linear Regression')\n",
    "\n",
    "# Add a grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "# Show\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #0072CE;\" />\n",
    "\n",
    "# Woohoo! You're all done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
